{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "264536d4",
   "metadata": {},
   "source": [
    "**Breakdown of Scraping Notebook**\n",
    "\n",
    "0. Import required packages, set variables, etc. Open up an instance of Selenium webdriver.\n",
    "1. Check for existence of TCN files for the specific year.\n",
    "    - If they're not there, build TCN files. They need to include the following and be saved in a separate directory.\n",
    "        - Year\n",
    "        - Team Name (per NCAA)\n",
    "        - UID\n",
    "        - Team Conference (abbreviated as NCAA does)\n",
    "        - Year-specific Team Number (from URL/href)\n",
    "    - If they're there, proceed.\n",
    "2. Loop over the TCN files. Get the data that is available from the team pages.\n",
    "3. Save the data in year-specific and overall files, both XLSX and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73eac1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define key functions\n",
    "def BecomeTeamInUID(teamName):\n",
    "    return teamName.replace(\" (\", \"-\").replace(\")\", \"\").replace(\".\", \"\").replace(\" \", \"\")\n",
    "def TeamWithoutParens(teamName):\n",
    "    return teamName.replace(\" (\", \"-\").replace(\")\", \"\")\n",
    "def BecomeUID(teamName, year, sport_abbr):\n",
    "    newTeamName = BecomeTeamInUID(teamName)\n",
    "    outputUID = f\"{year}.{sport_abbr}.{newTeamName}\"\n",
    "    return outputUID\n",
    "def TeamsToUIDs(teamList, year, sport_abbr):\n",
    "    uidList = []\n",
    "    for team in teamList:\n",
    "        uidList.append(BecomeUID(team, year, sport_abbr))\n",
    "    return uidList\n",
    "def DetectLocationDropRanking(opp, locNote):\n",
    "    opp = opp.strip()\n",
    "    # opponent is in one of the following formats. First detect home/away/neutral\n",
    "    # \"@ opp name\" or \"@ #xy opp name\" or \"@ #xyopp name\"\n",
    "    if (opp[0] == \"@\" and opp[1] == \" \"):\n",
    "        newOpp = opp[2:]\n",
    "        location = \"Away\"\n",
    "    # \"@opp name\" or \"@#xy opp name\" or \"@#xyoppname\"\n",
    "    elif (opp[0] == \"@\" and opp[1] != \" \"):\n",
    "        newOpp = opp[1:]\n",
    "        location = \"Away\"\n",
    "    # \"opp name\" or \"oppname\" or \"#xy oppname\" or \"#xyoppname\"\n",
    "    elif locNote != \"\":\n",
    "        newOpp = opp\n",
    "        location = \"Neutral\"\n",
    "    else:\n",
    "        newOpp = opp\n",
    "        location = \"Home\"\n",
    "    # Now, newOpp is in one of the following formats:\n",
    "    # \"#xy opp name\" or \"#xyopp name\"\n",
    "    if (newOpp[0] == \"#\" and newOpp[1].isnumeric() and newOpp[2].isnumeric()):\n",
    "        actualOpp = newOpp[3:]\n",
    "    # \"#x opp name\" or \"#xoppname\"\n",
    "    elif (newOpp[0] == \"#\" and newOpp[1].isnumeric()):\n",
    "        actualOpp = newOpp[2:]\n",
    "    else:\n",
    "        actualOpp = newOpp\n",
    "    actualOpp = actualOpp.strip()\n",
    "    return (actualOpp, location)\n",
    "\n",
    "def DropRanking(team):\n",
    "    # team is in the format: \"#x team name\" or \"#xy team name\" or #xyteam name. outputs \"team name\"\n",
    "    poundIndex = team.find(\"#\")\n",
    "    spaceIndex = team.find(\" \", poundIndex)\n",
    "    if poundIndex == -1:\n",
    "        return team\n",
    "    else:\n",
    "        return team[:poundIndex] + team[(spaceIndex + 1):]\n",
    "\n",
    "def ReturnLongestDF(dfList):\n",
    "    if len(dfList) == 1:\n",
    "        return dfList[0]\n",
    "    else:\n",
    "        longestDF = dfList[0]\n",
    "        for i in range(len(dfList) - 1):\n",
    "            if len(dfList[i+1]) > len(longestDF):\n",
    "                longestDF = dfList[i+1]\n",
    "        return longestDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae099786",
   "metadata": {},
   "source": [
    "**First step**: Leverage team leaderboard page to get \"TCN\" (team-conference-number) files that will help in building URLs for the next phase of the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43e01e0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import os\n",
    "import io\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import datetime # added 2-3-24\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "sport = \"Softball\"\n",
    "sport_abbr = \"SB\"\n",
    "minYear = 2021\n",
    "maxYear = 2024\n",
    "division = \"1.0\"\n",
    "years = np.flip(np.arange(minYear, maxYear + 1))\n",
    "baseURL = \"https://stats.ncaa.org/rankings/national_ranking?academic_year=2024.0&division=1.0&ranking_period=88.0&sport_code=WSB&stat_seq=320.0\"\n",
    "tcnOutputPath = os.getcwd() + \"\\\\TCN-Files\"\n",
    "statOutputPath = os.getcwd() + \"\\\\Stat-Files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af19ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service()\n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.implicitly_wait(15)\n",
    "\n",
    "# Build TCN files.\n",
    "for year in years:\n",
    "    # Go to 2024 win-loss percentage page\n",
    "    driver.get(baseURL)\n",
    "    \n",
    "    # Select Academic Year.\n",
    "    AcadYr = str(year - 1) + \"-\" + str(year)[2:]\n",
    "    selectYR = Select(driver.find_element(By.NAME, 'acadyr'))\n",
    "    selectYR.select_by_visible_text(AcadYr)\n",
    "    \n",
    "    # Select maximum number of teams.\n",
    "    selectNumTeams = Select(driver.find_element(By.NAME, 'rankings_table_length'))\n",
    "    selectNumTeams.select_by_value(\"-1\")   # This selects the greatest number from the dropdown list.\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Get team numbers from table\n",
    "    teamNumbers = []\n",
    "    table = driver.find_element(By.ID, \"rankings_table\")\n",
    "    result = BeautifulSoup(table.get_attribute('innerHTML'), 'lxml')\n",
    "    rows = result.find_all('tr')\n",
    "    for row in rows:\n",
    "        link = row.find('a', href=True)\n",
    "        if link:\n",
    "            extension = link['href']\n",
    "            teamNum = extension[7:]\n",
    "            teamNumbers.append(teamNum)\n",
    "    \n",
    "    WLTableDF = pd.read_html(io.StringIO(driver.page_source))[1]\n",
    "    \n",
    "    # Split the team into team and conference\n",
    "    teams = []\n",
    "    conferences = []\n",
    "    for teamConf in WLTableDF[\"Team\"]:\n",
    "        if teamConf.find(\"Reclass\") != -1:\n",
    "            break\n",
    "        splitIndex = teamConf.rfind(\"(\")\n",
    "        teams.append(TeamWithoutParens(teamConf[:(splitIndex-1)]))\n",
    "        conferences.append(teamConf[(splitIndex+1):-1])\n",
    "    uidList = TeamsToUIDs(teams, str(year), sport_abbr)\n",
    "    \n",
    "    # Construct TCN Dataframe\n",
    "    tcnDF = pd.DataFrame({\"Year\" : [year] * len(teams),\n",
    "                          \"Team\" : teams,\n",
    "                          \"Conference\" : conferences,\n",
    "                          \"UID\" : uidList,\n",
    "                          \"YearTeamNumbers\" : teamNumbers})\n",
    "    tcnDF.to_csv(tcnOutputPath + f\"\\\\{year}_TCN.csv\")\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56196cd",
   "metadata": {},
   "source": [
    "**Next Step:** Use the TCN files to obtain data from individual team pages.\n",
    "\n",
    "The data that is helpful for these analyses include the following for each game:\n",
    "- Date\n",
    "- Team\n",
    "- Team UID\n",
    "- Opponent\n",
    "- Opponent UID\n",
    "- Win/Loss/Tie\n",
    "- Location\n",
    "- Runs Scored\n",
    "- Runs Against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44604da6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team 1 of 22 in 2022 completed with 60 rows. Now saving...\n",
      "Team 2 of 22 in 2022 completed with 63 rows. Now saving...\n",
      "Team 3 of 22 in 2022 completed with 68 rows. Now saving...\n",
      "Team 4 of 22 in 2022 completed with 59 rows. Now saving...\n",
      "Team 5 of 22 in 2022 completed with 59 rows. Now saving...\n",
      "Team 6 of 22 in 2022 completed with 43 rows. Now saving...\n",
      "Team 7 of 22 in 2022 completed with 55 rows. Now saving...\n",
      "Team 8 of 22 in 2022 completed with 60 rows. Now saving...\n",
      "Team 9 of 22 in 2022 completed with 51 rows. Now saving...\n",
      "Team 10 of 22 in 2022 completed with 54 rows. Now saving...\n",
      "Team 11 of 22 in 2022 completed with 57 rows. Now saving...\n",
      "Team 12 of 22 in 2022 completed with 47 rows. Now saving...\n",
      "Team 13 of 22 in 2022 completed with 45 rows. Now saving...\n",
      "Team 14 of 22 in 2022 completed with 54 rows. Now saving...\n",
      "Team 15 of 22 in 2022 completed with 52 rows. Now saving...\n",
      "Team 16 of 22 in 2022 completed with 45 rows. Now saving...\n",
      "Team 17 of 22 in 2022 completed with 50 rows. Now saving...\n",
      "Team 18 of 22 in 2022 completed with 47 rows. Now saving...\n",
      "Team 19 of 22 in 2022 completed with 47 rows. Now saving...\n",
      "Team 20 of 22 in 2022 completed with 46 rows. Now saving...\n",
      "Team 21 of 22 in 2022 completed with 51 rows. Now saving...\n",
      "Team 22 of 22 in 2022 completed with 51 rows. Now saving...\n",
      "2022 addendum completed.\n"
     ]
    }
   ],
   "source": [
    "# Columns for output DF\n",
    "dfColumns = [\"Year\", \"Date\", \"Team\", \"TeamUID\", \"TeamConference\", \"Opponent\", \"OppUID\", \"OppConference\",\n",
    "             \"Location\", \"Conference\", \"Win\", \"Loss\", \"Tie\", \"RunsFor\", \"RunsAgainst\"]\n",
    "\n",
    "# Year -> End date of regular season/conference tournaments\n",
    "Year_to_RSEndDate = {2023 : datetime.date(2023, 5, 15), \n",
    "                     2022 : datetime.date(2022, 5, 16), \n",
    "                     2021 : datetime.date(2021, 5, 17)}\n",
    "\n",
    "service = Service()\n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "driver.implicitly_wait(30)\n",
    "\n",
    "# Create overall DF.\n",
    "overallDF = pd.DataFrame(columns=dfColumns)\n",
    "\n",
    "# Loop over years\n",
    "for year in [2022]:\n",
    "    tcnDF = pd.read_csv(tcnOutputPath + f\"\\\\{year}_TCN.csv\")\n",
    "    tcnToFixDF = pd.read_csv(\"TeamsToCorrect2_TCN.csv\")\n",
    "    tcnToFixDF = tcnToFixDF[tcnToFixDF[\"Year\"] == year]\n",
    "    tcnToFixDF.reset_index(inplace=True, drop=True)\n",
    "    yearDF = pd.DataFrame(columns=dfColumns)\n",
    "    # Loop over teams in years\n",
    "    for teamIndex in range(len(tcnToFixDF)):\n",
    "        team = tcnToFixDF.loc[teamIndex, \"Team\"]\n",
    "        teamYearNum = tcnToFixDF.loc[teamIndex, \"YearTeamNumbers\"]\n",
    "        # Go to team homepage then the batting page.\n",
    "        teamURL = f\"https://stats.ncaa.org/teams/{teamYearNum}\"\n",
    "        driver.get(teamURL)\n",
    "        while True:\n",
    "            try:\n",
    "                driver.find_element(By.XPATH, \"/html/body/div[2]/div/div/div/div/div/nav/ul/li[4]/a\")\n",
    "            except:\n",
    "                time.sleep(2)\n",
    "                driver.refresh()\n",
    "            else:\n",
    "                break\n",
    "        htmlToReplace = '</a> <br>'\n",
    "        replacementHTML = '</a> <br>SPLIT'\n",
    "        # Go to hitting stats page (Game By Game)\n",
    "        time.sleep(2)\n",
    "        driver.find_element(By.XPATH, \"/html/body/div[2]/div/div/div/div/div/nav/ul/li[4]/a\").click()\n",
    "        while True:\n",
    "            try:\n",
    "                driver.find_element(By.XPATH, '/html/body/div[2]/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div/div[1]/div[1]')\n",
    "            except:\n",
    "                time.sleep(2)\n",
    "                driver.refresh()\n",
    "            else:\n",
    "                break\n",
    "        battingTable = driver.find_element(By.ID, f\"game_breakdown_div\").get_attribute('innerHTML')\n",
    "        battingTable = battingTable.replace(htmlToReplace, replacementHTML)\n",
    "        battingDFs = pd.read_html(io.StringIO(battingTable))\n",
    "        # Some pages don't have the actual stat table as the first entry, we have to pick which one we want.\n",
    "        battingDF = ReturnLongestDF(battingDFs)\n",
    "        # Go to pitching stats page\n",
    "        time.sleep(2)\n",
    "        driver.find_element(By.XPATH, \"/html/body/div[2]/div/div/div/div/div/nav[2]/ul/li[2]/a\").click()\n",
    "        while True:\n",
    "            try:\n",
    "                driver.find_element(By.XPATH, '/html/body/div[2]/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div/div[1]/div[1]')\n",
    "            except:\n",
    "                time.sleep(2)\n",
    "                driver.refresh()\n",
    "            else:\n",
    "                break\n",
    "        pitchingTable = driver.find_element(By.ID, f\"game_breakdown_div\").get_attribute('innerHTML')\n",
    "        pitchingTable = pitchingTable.replace(htmlToReplace, replacementHTML)\n",
    "        pitchingDFs = pd.read_html(io.StringIO(pitchingTable))\n",
    "        pitchingDF = ReturnLongestDF(pitchingDFs)\n",
    "        \n",
    "        # Get rid of battingDF and pitchingDF rows where there isn't a result.\n",
    "        battingDF.dropna(subset=['Result'], inplace=True)\n",
    "        pitchingDF.dropna(subset=['Result'], inplace=True)\n",
    "        battingDF.reset_index(inplace=True, drop=True)\n",
    "        pitchingDF.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        # Combine dataframes\n",
    "        teamDF = pd.DataFrame({\"Year\" : [year] * len(battingDF),\n",
    "                                \"Date\" : battingDF[\"Date\"],\n",
    "                                \"Team\": [team] * len(battingDF),\n",
    "                                \"Opponent\" : battingDF[\"Opponent\"],\n",
    "                                \"Result\" : battingDF[\"Result\"],\n",
    "                                \"RunsFor\" : battingDF[\"R\"], \n",
    "                                \"RunsAgainst\" : pitchingDF[\"R\"]})\n",
    "        # Fill in missing values with 0.\n",
    "        teamDF = teamDF.fillna(0)\n",
    "        \n",
    "        \n",
    "        # Get rid of summary/canceled game columns + add W/L/T columns\n",
    "        wins = []\n",
    "        losses = []\n",
    "        ties = []\n",
    "        rowsToDrop = []\n",
    "        for i in range(len(teamDF)):\n",
    "            result = teamDF.loc[i, \"Result\"]\n",
    "            resultStart = result[:2]\n",
    "            opp = teamDF.loc[i, \"Opponent\"]\n",
    "            if resultStart[:2] == \"W \":\n",
    "                wins.append(1); losses.append(0); ties.append(0);\n",
    "            elif resultStart[:2] == \"L \":\n",
    "                wins.append(0); losses.append(1); ties.append(0);\n",
    "            elif resultStart[:2] == \"T \":\n",
    "                wins.append(0); losses.append(0); ties.append(1);\n",
    "            else:\n",
    "                rowsToDrop.append(i)\n",
    "        teamDF.drop(rowsToDrop, axis=0, inplace=True)\n",
    "        teamDF[\"Win\"] = wins\n",
    "        teamDF[\"Loss\"] = losses\n",
    "        teamDF[\"Tie\"] = ties\n",
    "        teamDF.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        # Split Opponent into Opponent and Location Note\n",
    "        newOpponents = []\n",
    "        locationNotes = []\n",
    "        for i in range(len(teamDF)):\n",
    "            oldOpponent = teamDF.loc[i, \"Opponent\"]\n",
    "            findSplit = oldOpponent.find(\"SPLIT\")\n",
    "            if findSplit == -1: # it's normal\n",
    "                newOpponents.append(oldOpponent)\n",
    "                locationNotes.append(\"\")\n",
    "            else: # we have a SPLIT\n",
    "                newOpponents.append(oldOpponent[:(findSplit - 1)])\n",
    "                locationNotes.append(oldOpponent[(findSplit + 5):])\n",
    "        teamDF[\"Opponent\"] = newOpponents\n",
    "        teamDF[\"LocationNote\"] = locationNotes\n",
    "        \n",
    "        \n",
    "        # Clean Up Opponent Column, add location column\n",
    "        locations = []\n",
    "        newOpponents = []\n",
    "        for i in range(len(teamDF)):\n",
    "            opp = teamDF.loc[i, \"Opponent\"]\n",
    "            locNote = teamDF.loc[i, \"LocationNote\"]\n",
    "            (actualOpp, location) = DetectLocationDropRanking(opp, locNote)\n",
    "            locations.append(location)\n",
    "            newOpponents.append(actualOpp)\n",
    "        teamDF[\"Location\"] = locations\n",
    "        teamDF[\"Opponent\"] = newOpponents\n",
    "        teamDF.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        \n",
    "        # Add UIDs\n",
    "        teamDF[\"TeamUID\"] = TeamsToUIDs(teamDF[\"Team\"], year, sport_abbr)\n",
    "        teamDF[\"OppUID\"] = TeamsToUIDs(teamDF[\"Opponent\"], year, sport_abbr)\n",
    "        \n",
    "        # Add Conferences\n",
    "        teamDF = teamDF.merge(tcnDF[[\"UID\", \"Conference\"]], left_on=\"TeamUID\", right_on=\"UID\")\n",
    "        teamDF.rename(columns={\"Conference\" : \"TeamConference\"}, inplace=True)\n",
    "        teamDF.drop(columns=[\"UID\"], inplace=True)\n",
    "        teamDF = teamDF.merge(tcnDF[[\"UID\", \"Conference\"]], left_on=\"OppUID\", right_on=\"UID\")\n",
    "        teamDF.rename(columns={\"Conference\" : \"OppConference\"}, inplace=True)\n",
    "        teamDF.drop(columns=[\"UID\"], inplace=True)\n",
    "        \n",
    "        # Add conference column\n",
    "        teamDF[\"Conference\"] = [1 if (teamDF.loc[j, \"TeamConference\"] == teamDF.loc[j, \"OppConference\"])\n",
    "                                else 0 for j in range(len(teamDF)) ]\n",
    "        \n",
    "        # Cut teamDF down to only the columns that it's supposed to have.\n",
    "        teamDF = teamDF[dfColumns]\n",
    "        \n",
    "        # Merge into yearDF\n",
    "        yearDF = pd.concat([yearDF, teamDF])\n",
    "        \n",
    "        # Save every team\n",
    "        print(f\"Team {teamIndex + 1} of {len(tcnToFixDF)} in {year} completed with {len(teamDF)} rows. Now saving...\")\n",
    "        yearDF.to_csv(f\"SB_{year}_DPGameByGame_Addendum.csv\")\n",
    "    \n",
    "    # Save yearly\n",
    "    print(f\"{year} addendum completed.\")\n",
    "    yearDF.to_csv(f\"SB_{year}_DPGameByGame_Addendum.csv\")\n",
    "\n",
    "    # Append yearDF and save\n",
    "    overallDF = pd.concat([overallDF, yearDF])\n",
    "    overallDF.to_csv(f\"SB_{year}to{maxYear}_DPGameByGame_Addendum.csv\")\n",
    "    \n",
    "# Save Overall File\n",
    "#overallDF.to_csv(statOutputPath + f\"\\\\SB_{minYear}to{maxYear}_DPGameByGame.csv\")\n",
    "\n",
    "overallDF.to_csv(f\"SB_{minYear}to{maxYear}_DPGameByGame_Addendum.csv\")\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1113f5ba",
   "metadata": {},
   "source": [
    "Last Step: Cleaning Data\n",
    "\n",
    "We want to get the \"Date\" column in the proper form (without any (1) to indicate the first game of a doubleheader and (2) to indicate the second game of a doubleheader) and the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39e87630",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearDFList = []\n",
    "for year in years:\n",
    "    yearDF = pd.read_csv(statOutputPath + f\"\\\\SB_{year}_DPGameByGame.csv\")\n",
    "    yearDF[\"Date\"] = [yearDF.loc[i, \"Date\"].replace(\"(1)\", \"\").replace(\"(2)\", \"\").replace(\"(3)\", \"\") for i in range(len(yearDF))]\n",
    "    yearDF[\"Date\"] = pd.to_datetime(yearDF[\"Date\"])\n",
    "    yearDF[\"RunsFor\"] = [int(float(yearDF.loc[i, \"RunsFor\"].replace(\"/\",\"\"))) for i in range(len(yearDF))]\n",
    "    yearDF[\"RunsAgainst\"] = [int(float(yearDF.loc[i, \"RunsAgainst\"].replace(\"/\",\"\"))) for i in range(len(yearDF))]\n",
    "    yearDF.to_csv(statOutputPath + f\"\\\\SB_{year}_DPGameByGame.csv\")\n",
    "    yearDFList.append(yearDF)\n",
    "yearsDF = pd.concat(yearDFList)\n",
    "yearsDF.to_csv(statOutputPath + f\"\\\\SB_{minYear}to{maxYear}_DPGameByGame.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
